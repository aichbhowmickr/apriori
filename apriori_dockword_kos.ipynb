{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "data =pd.read_csv(\"docword_kos.txt\",skiprows=3,header=None,sep= \" \",names=[\"docId\",\"wordId\",\"count\"])\n",
    "data_clean=data.groupby([\"docId\",\"wordId\"])[\"count\"].sum().unstack().reset_index().fillna(0).set_index(\"docId\")\n",
    "data_clean[data_clean>0]=1\n",
    "\n",
    "#set of all transactions\n",
    "Transactions=[]\n",
    "for id in data_clean.index:\n",
    "    ls=np.flatnonzero(data_clean.loc[id]).tolist()\n",
    "    ls1=[item+1 for item in ls]\n",
    "    ls2=set(ls1)\n",
    "    Transactions.append(ls2)\n",
    "\n",
    "#candidate-gen function\n",
    "def candidate_gen(f):\n",
    "    c_set=[]\n",
    "    c=set()\n",
    "    for f1 in f:\n",
    "        for f2 in f :\n",
    "            if (((f2.difference(f1)).union(f1.difference(f2))=={max(f1),max(f2)})&(max(f1)<max(f2))):\n",
    "                c =f1.union({max(f2)})\n",
    "                c_set.append(c)\n",
    "               \n",
    "                for i in c:\n",
    "                    if c.difference({i}) not in f:\n",
    "                        \n",
    "                        if (c_set != []) & (c in c_set):\n",
    "                           \n",
    "                            c_set.remove(c)\n",
    "    \n",
    "    return c_set\n",
    "\n",
    "#counts the frequency of a candidate set\n",
    "def support_count_of_sets(input_set):\n",
    "    count=0\n",
    "    for t in Transactions:\n",
    "        if input_set.issubset(t):\n",
    "            count =count+1\n",
    "    return count\n",
    "    \n",
    "\n",
    "# apriori function\n",
    "def apriori(data_clean,min_sup,k):\n",
    "    c1=[]\n",
    "    f=[]\n",
    "    no_of_transactions=max(data_clean.index)\n",
    "    start_time=time.time()\n",
    "    for item in data_clean.columns:\n",
    "        c1.append(set([item]))\n",
    "        \n",
    "    for item in data_clean.columns:\n",
    "        if ((data_clean[item].sum())/no_of_transactions)>=min_sup:\n",
    "            f.append(set([item]))\n",
    "    final_f=[]\n",
    "    final_f=final_f+f\n",
    "   \n",
    "    \n",
    "    for i in range(2,k+1):\n",
    "        \n",
    "        c_set=candidate_gen(f)\n",
    "        \n",
    "        temp=len(f)\n",
    "        for item in c_set:\n",
    "            \n",
    "            if (  support_count_of_sets(item) /no_of_transactions)>=min_sup:\n",
    "                f.append(item)                           #  now f contains k-1,k length frequent item sets\n",
    "                             \n",
    "        f=f[temp:]                                       # this removes k-1 length frequent item sets from f\n",
    "        final_f=final_f+f                                # appends all k length frequent items to f_final\n",
    "    end_time  =time.time() \n",
    "    print(\"F=\",min_sup)\n",
    "    print(\"K=\",k)\n",
    "    print(\"Runtime is :\"+str(end_time-start_time)+\" seconds\")\n",
    "    print(\"The Frequent sets are:\")\n",
    "    print(final_f)\n",
    "    return final_f\n",
    "\n",
    "apriori(data_clean,.1,5)\n",
    "\n",
    "apriori(data_clean,.2,10)\n",
    "\n",
    "apriori(data_clean,.4,10)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
